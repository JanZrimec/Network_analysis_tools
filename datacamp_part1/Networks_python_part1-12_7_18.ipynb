{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## script does not run only notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Course Data Camp notes\n",
    "\n",
    "# datasets used in tutorial cannot be imported possibly due to\n",
    "# nx version vas < 1.9, running in python v eg 3.1, which is not supported in conda, \n",
    "# and higher python versions are not supported in nx\n",
    "\n",
    "## SOLUTION:\n",
    "## nx ver 1.11 -> py 3.6 compatible\n",
    "\n",
    "# conda create -name nx11py36 python=3.6\n",
    "# conda install matplotlib\n",
    "# conda install networkx=1.11\n",
    "\n",
    "# conda config --add channels conda-forge\n",
    "# conda install nxviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data loading issues:\n",
    "# https://networkx.github.io/documentation/stable/release/migration_guide_from_1.x_to_2.0.html\n",
    "\n",
    "# V1 and V2 not compatible\n",
    "# Using Pickle with v1 and v2\n",
    "# The Pickle protocol does not store class methods, only the data. So if you write a pickle file with v1 you should not expect to read it into a v2 Graph. If this happens to you, read it in with v1 installed and write a file with the node and edge information. You can read that into a config with v2 installed and then add those nodes and edges to a fresh graph. Try something similar to this:\n",
    "\n",
    "# >>> # in v1.x\n",
    "# >>> pickle.dump([G.nodes(data=True), G.edges(data=True)], file)  \n",
    "# >>> # then in v2.x\n",
    "# >>> nodes, edges = pickle.load(file)  \n",
    "# >>> G = nx.Graph()  \n",
    "# >>> G.add_nodes_from(nodes)  \n",
    "# >>> G.add_edges_from(edges)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick search plotting tools:\n",
    "# plotly\n",
    "# https://plot.ly/python/3d-network-graph/\n",
    "# networkx\n",
    "# https://python-graph-gallery.com/network-chart/\n",
    "# https://python-graph-gallery.com/chord-diagram/\n",
    "\n",
    "\n",
    "# Network analysis in Python 1 - overview of important information\n",
    "# Eric Ma\n",
    "# has also other interesting tutorials\n",
    "# https://github.com/ericmjl/Network-Analysis-Made-Simple\n",
    "# and video tutorials for this\n",
    "# shorter (2.5h): https://www.youtube.com/watch?v=E4VKzFmByhE\n",
    "# longer (6.5h): https://www.youtube.com/watch?v=HkbMUrgzwMs, https://www.youtube.com/watch?v=MRCLwmYTVpc\n",
    "\n",
    "\n",
    "# Connected necessary content:\n",
    "# https://www.datacamp.com/community/tutorials/python-list-comprehension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import nxviz as nv\n",
    "from nxviz import MatrixPlot\n",
    "from nxviz import ArcPlot\n",
    "from nxviz import CircosPlot\n",
    "\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download files from datacamp\n",
    "\n",
    "T = pickle.load(open('ego-twitter.p','rb'))\n",
    "G = pickle.load(open('github_users.p','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chapter 1\n",
    "\n",
    "# Network visualization\n",
    "# matrix\n",
    "# arc\n",
    "# circos\n",
    "# nxviz plotting tool developed by lecturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics of NetworkX API\n",
    "# What is the size of the graph T, the type of T.nodes(), and the data structure of the \n",
    "# third element of the last entry of T.edges(data=True)? The len() and type() functions will be useful here. \n",
    "# To access the last entry of T.edges(data=True), you can use T.edges(data=True)[-1].\n",
    "\n",
    "# Draw the graph to screen\n",
    "# nx.draw(T_sub)\n",
    "# plt.show()\n",
    "\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T.nodes(data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries on a graph\n",
    "# Now that you know some basic properties of the graph and have practiced using NetworkX's drawing facilities to visualize components of it, it's time to explore how you can query it for nodes and edges. Specifically, you're going to look for \"nodes of interest\" and \"edges of interest\". To achieve this, you'll make use of the .nodes() and .edges() methods that Eric went over in the video. The .nodes() method returns a list of nodes, while the .edges() method returns a list of tuples, in which each tuple shows the nodes that are present on that edge. Recall that passing in the keyword argument data=True in these methods retrieves the corresponding metadata associated with the nodes and edges as well.\n",
    "# You'll write list comprehensions to effectively build these queries in one line. For a refresher on list comprehensions, refer to Part 2 of DataCamp's Python Data Science Toolbox course. Here's the recipe for a list comprehension:\n",
    "# [ output expression for iterator variable in iterable if predicate expression ].\n",
    "# You have to fill in the _iterable_ and the _predicate expression_. Feel free to prototype your answer by exploring the graph in the IPython Shell before submitting your solution.\n",
    "\n",
    "# Use a list comprehension to get the nodes of interest: noi\n",
    "noi = [n for n, d in T.nodes(data=True) if d['occupation'] == 'scientist']\n",
    "\n",
    "# Use a list comprehension to get the edges of interest: eoi\n",
    "eoi = [(u, v) for u, v, d in T.edges(data=True) if d['date'] < date(2010,1,1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying a weight on edges\n",
    "# Weights can be added to edges in a graph, typically indicating the \"strength\" of an edge. In NetworkX, the weight is indicated by the 'weight' key in the metadata dictionary.\n",
    "# Before attempting the exercise, use the IPython Shell to access the dictionary metadata of T and explore it, for instance by running the commands T.edge[1][10] and then T.edge[10][1]. Note how there's only one field, and now you're going to add another field, called 'weight'.\n",
    "\n",
    "# Set the weight of the edge\n",
    "T.edge[1][10]['weight'] = 2\n",
    "\n",
    "# Iterate over all the edges (with metadata)\n",
    "for u, v, d in T.edges(data=True):\n",
    "\n",
    "    # Check if node 293 is involved\n",
    "    if 293 in [u,v]:\n",
    "    \n",
    "        # Set the weight to 1.1\n",
    "        T.edge[u][v]['weight'] = 1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether there are self-loops in the graph\n",
    "# As Eric discussed, NetworkX also allows edges that begin and end on the same node; while this would be non-intuitive for a social network graph, it is useful to model data such as trip networks, in which individuals begin at one location and end in another.\n",
    "# It is useful to check for this before proceeding with further analyses, and NetworkX graphs provide a method for this purpose: .number_of_selfloops().\n",
    "# In this exercise as well as later ones, you'll find the assert statement useful. An assert-ions checks whether the statement placed after it evaluates to True, otherwise it will return an AssertionError.\n",
    "# To begin, use the .number_of_selfloops() method on T in the IPython Shell to get the number of edges that begin and end on the same node. A number of self-loops have been synthetically added to the graph. Your job in this exercise is to write a function that returns these edges.\n",
    "\n",
    "# Define find_selfloop_nodes()\n",
    "def find_selfloop_nodes(G):\n",
    "    \"\"\"\n",
    "    Finds all nodes that have self-loops in the graph G.\n",
    "    \"\"\"\n",
    "    nodes_in_selfloops = []\n",
    "    \n",
    "    # Iterate over all the edges of G\n",
    "    for u, v in G.edges():\n",
    "    \n",
    "    # Check if node u and node v are the same\n",
    "        if u == v:\n",
    "        \n",
    "            # Append node u to nodes_in_selfloops\n",
    "            nodes_in_selfloops.append(u)\n",
    "            \n",
    "    return nodes_in_selfloops\n",
    "\n",
    "# Check whether number of self loops equals the number of nodes in self loops\n",
    "assert T.number_of_selfloops() == len(find_selfloop_nodes(T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert T to a matrix format: A\n",
    "A = nx.to_numpy_matrix(T)\n",
    "\n",
    "# Convert A back to the NetworkX form as a directed graph: T_conv\n",
    "T_conv = nx.from_numpy_matrix(A, create_using=nx.DiGraph())\n",
    "\n",
    "# Check that the `category` metadata field is lost from each node\n",
    "for n, d in T_conv.nodes(data=True):\n",
    "    assert 'category' not in d.keys()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing using nxviz\n",
    "# It is time to try your first \"fancy\" graph visualization method: a matrix plot. To do this, nxviz provides a MatrixPlot object.\n",
    "# nxviz is a package for visualizing graphs in a rational fashion. Under the hood, the MatrixPlot utilizes nx.to_numpy_matrix(G), which returns the matrix form of the graph. Here, each node is one column and one row, and an edge between the two nodes is indicated by the value 1. In doing so, however, only the weight metadata is preserved; all other metadata is lost, as you'll verify using an assert statement.\n",
    "# A corresponding nx.from_numpy_matrix(A) allows one to quickly create a graph from a NumPy matrix. The default graph type is Graph(); if you want to make it a DiGraph(), that has to be specified using the create_using keyword argument, e.g. (nx.from_numpy_matrix(A, create_using=nx.DiGraph)).\n",
    "# One final note, matplotlib.pyplot and networkx have already been imported as plt and nx, respectively, and the graph T has been pre-loaded. For simplicity and speed, we have sub-sampled only 100 edges from the network.\n",
    "\n",
    "\n",
    "# Create the MatrixPlot object: m\n",
    "m = nv.MatrixPlot(T)\n",
    "\n",
    "# Draw m to the screen\n",
    "m.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(T)\n",
    "\n",
    "# Draw c to the screen\n",
    "c.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the un-customized ArcPlot object: a\n",
    "a = ArcPlot(T)\n",
    "\n",
    "# Draw a to the screen\n",
    "a.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the customized ArcPlot object: a2\n",
    "a2 = ArcPlot(T, node_order = 'category', node_color = 'category')\n",
    "\n",
    "# Draw a2 to the screen\n",
    "a2.draw()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chapter 2\n",
    "# neighbors\n",
    "# degree\n",
    "# betweenness\n",
    "# centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of neighbors for each node\n",
    "# How do you evaluate whether a node is an important one or not? There are a few ways to do so, and here, you're going to look at one metric: the number of neighbors that a node has.\n",
    "# Every NetworkX graph G exposes a .neighbors(n) method that returns a list of nodes that are the neighbors of the node n. To begin, use this method in the IPython Shell on the Twitter network T to get the neighbors of of node 1. This will get you familiar with how the function works. Then, your job in this exercise is to write a function that returns all nodes that have m neighbors.\n",
    "\n",
    "\n",
    "# Define nodes_with_m_nbrs()\n",
    "def nodes_with_m_nbrs(G, m):\n",
    "    \"\"\"\n",
    "    Returns all nodes in graph G that have m neighbors.\n",
    "    \"\"\"\n",
    "    nodes = set()\n",
    "    \n",
    "    # Iterate over all nodes in G\n",
    "    for n in G.nodes():\n",
    "    \n",
    "        # Check if the number of neighbors of n matches m\n",
    "        if len(G.neighbors(n)) == m:\n",
    "        \n",
    "            # Add the node n to the set\n",
    "            nodes.add(n)\n",
    "            \n",
    "    # Return the nodes with m neighbors\n",
    "    return nodes\n",
    "\n",
    "# Compute and print all nodes in T that have 6 neighbors\n",
    "six_nbrs = nodes_with_m_nbrs(T, 6)\n",
    "print(six_nbrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute degree distribution\n",
    "# The number of neighbors that a node has is called its \"degree\", and it's possible to compute the degree distribution across the entire graph. In this exercise, your job is to compute the degree distribution across T.\n",
    "\n",
    "# Compute the degree of every node: degrees\n",
    "degrees = [len(T.neighbors(n)) for n in T.nodes()]\n",
    "\n",
    "# Print the degrees\n",
    "print(degrees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree centrality distribution\n",
    "# The degree of a node is the number of neighbors that it has. The degree centrality is the number of neighbors divided by all possible neighbors that it could have. Depending on whether self-loops are allowed, the set of possible neighbors a node could have could also include the node itself.\n",
    "# The nx.degree_centrality(G) function returns a dictionary, where the keys are the nodes and the values are their degree centrality values.\n",
    "\n",
    "\n",
    "# Compute the degree centrality of the Twitter network: deg_cent\n",
    "deg_cent = nx.degree_centrality(T)\n",
    "\n",
    "# Plot a histogram of the degree centrality distribution of the graph.\n",
    "plt.figure()\n",
    "plt.hist(list(deg_cent.values()))\n",
    "plt.show()\n",
    "\n",
    "# Plot a histogram of the degree distribution of the graph\n",
    "plt.figure()\n",
    "plt.hist(degrees)\n",
    "plt.show()\n",
    "\n",
    "# Plot a scatter plot of the centrality distribution and the degree distribution\n",
    "plt.figure()\n",
    "plt.scatter(degrees,list(deg_cent.values()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest Path\n",
    "\n",
    "def path_exists(G, node1, node2):\n",
    "    \"\"\"\n",
    "    This function checks whether a path exists between two nodes (node1, node2) in graph G.\n",
    "    \"\"\"\n",
    "    visited_nodes = set()\n",
    "    queue = [node1]\n",
    "    \n",
    "    for node in queue:  \n",
    "        neighbors = G.neighbors(node)\n",
    "        if node2 in neighbors:\n",
    "            print('Path exists between nodes {0} and {1}'.format(node1, node2))\n",
    "            return True\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            visited_nodes.add(node)\n",
    "            queue.extend([n for n in neighbors if n not in visited_nodes])\n",
    "        \n",
    "        # Check to see if the final element of the queue has been reached\n",
    "        if node == queue[-1]:\n",
    "            print('Path does not exist between nodes {0} and {1}'.format(node1, node2))\n",
    "\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkX betweenness centrality on a social network\n",
    "# Betweenness centrality is a node importance metric that uses information about the shortest paths in a network. It is defined as the fraction of all possible shortest paths between any pair of nodes that pass through the node.\n",
    "# NetworkX provides the nx.betweenness_centrality(G) function for computing the betweenness centrality of every node in a graph, and it returns a dictionary where the keys are the nodes and the values are their betweenness centrality measures.\n",
    "\n",
    "# Compute the betweenness centrality of T: bet_cen\n",
    "bet_cen = nx.betweenness_centrality(T)\n",
    "\n",
    "# Compute the degree centrality of T: deg_cen\n",
    "deg_cen = nx.degree_centrality(T)\n",
    "\n",
    "# Create a scatter plot of betweenness centrality and degree centrality\n",
    "plt.scatter(list(bet_cen.values()),list(deg_cen.values()))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep dive - Twitter network\n",
    "# You're going to now take a deep dive into a Twitter network, which will help reinforce what you've learned earlier. First, you're going to find the nodes that can broadcast messages very efficiently to lots of people one degree of separation away.\n",
    "# NetworkX has been pre-imported for you as nx.\n",
    "\n",
    "\n",
    "# Define find_nodes_with_highest_deg_cent()\n",
    "def find_nodes_with_highest_deg_cent(G):\n",
    "\n",
    "    # Compute the degree centrality of G: deg_cent\n",
    "    deg_cent = nx.degree_centrality(G)\n",
    "    \n",
    "    # Compute the maximum degree centrality: max_dc\n",
    "    max_dc = max(list(deg_cent.values()))\n",
    "    \n",
    "    nodes = set()\n",
    "    \n",
    "    # Iterate over the degree centrality dictionary\n",
    "    for k, v in deg_cent.items():\n",
    "    \n",
    "        # Check if the current value has the maximum degree centrality\n",
    "        if v == max_dc:\n",
    "        \n",
    "            # Add the current node to the set of nodes\n",
    "            nodes.add(k)\n",
    "            \n",
    "    return nodes\n",
    "    \n",
    "# Find the node(s) that has the highest degree centrality in T: top_dc\n",
    "top_dc = find_nodes_with_highest_deg_cent(T)\n",
    "print(top_dc)\n",
    "\n",
    "# Write the assertion statement\n",
    "for node in top_dc:\n",
    "    assert nx.degree_centrality(T)[node] == max(nx.degree_centrality(T).values())\n",
    "\n",
    "# Deep dive - Twitter network part II\n",
    "# Next, you're going to do an analogous deep dive on betweenness centrality! Just a few hints to help you along: remember that betweenness centrality is computed using nx.betweenness_centrality(G).\n",
    "\n",
    "# Define find_node_with_highest_bet_cent()\n",
    "def find_node_with_highest_bet_cent(G):\n",
    "\n",
    "    # Compute betweenness centrality: bet_cent\n",
    "    bet_cent = nx.betweenness_centrality(G)\n",
    "    \n",
    "    # Compute maximum betweenness centrality: max_bc\n",
    "    max_bc = max(list(bet_cent.values()))\n",
    "    \n",
    "    nodes = set()\n",
    "    \n",
    "    # Iterate over the betweenness centrality dictionary\n",
    "    for k, v in bet_cent.items():\n",
    "    \n",
    "        # Check if the current value has the maximum betweenness centrality\n",
    "        if v == max_bc:\n",
    "        \n",
    "            # Add the current node to the set of nodes\n",
    "            nodes.add(k)\n",
    "            \n",
    "    return nodes\n",
    "\n",
    "# Use that function to find the node(s) that has the highest betweenness centrality in the network: top_bc\n",
    "top_bc = find_node_with_highest_bet_cent(T)\n",
    "\n",
    "# Write an assertion statement that checks that the node(s) is/are correctly identified.\n",
    "for node in top_bc:\n",
    "    assert nx.betweenness_centrality(T)[node] == max(nx.betweenness_centrality(T).values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chapter 3\n",
    "# cliques (simple = edge, simplest complex = triangle)\n",
    "# maximal clique (maximal fully connected subgraph)\n",
    "# community\n",
    "# subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying triangle relationships\n",
    "# Now that you've learned about cliques, it's time to try leveraging what you know to find structures in a network. Triangles are what you'll go for first. We may be interested in triangles because they're the simplest complex clique. Let's write a few functions; these exercises will bring you through the fundamental logic behind network algorithms.\n",
    "# In the Twitter network, each node has an 'occupation' label associated with it, in which the Twitter user's work occupation is divided into celebrity, politician and scientist. One potential application of triangle-finding algorithms is to find out whether users that have similar occupations are more likely to be in a clique with one another.\n",
    "\n",
    "\n",
    "# Define is_in_triangle() \n",
    "def is_in_triangle(G, n):\n",
    "    \"\"\"\n",
    "    Checks whether a node `n` in graph `G` is in a triangle relationship or not. \n",
    "    \n",
    "    Returns a boolean.\n",
    "    \"\"\"\n",
    "    in_triangle = False\n",
    "    \n",
    "    # Iterate over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n), 2):\n",
    "    \n",
    "        # Check if an edge exists between n1 and n2\n",
    "        if G.has_edge(n1, n2):\n",
    "            in_triangle = True\n",
    "            break\n",
    "    return in_triangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding nodes involved in triangles\n",
    "# NetworkX provides an API for counting the number of triangles that every node is involved in: nx.triangles(G). It returns a dictionary of nodes as the keys and number of triangles as the values. Your job in this exercise is to modify the function defined earlier to extract all of the nodes involved in a triangle relationship with a given node.\n",
    "\n",
    "\n",
    "# Write a function that identifies all nodes in a triangle relationship with a given node.\n",
    "def nodes_in_triangle(G, n):\n",
    "    \"\"\"\n",
    "    Returns the nodes in a graph `G` that are involved in a triangle relationship with the node `n`.\n",
    "    \"\"\"\n",
    "    triangle_nodes = set([n])\n",
    "    \n",
    "    # Iterate over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n),2):\n",
    "    \n",
    "        # Check if n1 and n2 have an edge between them\n",
    "        if G.has_edge(n1, n2):\n",
    "        \n",
    "            # Add n1 to triangle_nodes\n",
    "            triangle_nodes.add(n1)\n",
    "            \n",
    "            # Add n2 to triangle_nodes\n",
    "            triangle_nodes.add(n2)\n",
    "            \n",
    "    return triangle_nodes\n",
    "    \n",
    "# Write the assertion statement\n",
    "assert len(nodes_in_triangle(T, 1)) == 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding open triangles\n",
    "# Let us now move on to finding open triangles! Recall that they form the basis of friend recommendation systems; if \"A\" knows \"B\" and \"A\" knows \"C\", then it's probable that \"B\" also knows \"C\".\n",
    "\n",
    "\n",
    "# Define node_in_open_triangle()\n",
    "def node_in_open_triangle(G, n):\n",
    "    \"\"\"\n",
    "    Checks whether pairs of neighbors of node `n` in graph `G` are in an 'open triangle' relationship with node `n`.\n",
    "    \"\"\"\n",
    "    in_open_triangle = False\n",
    "    \n",
    "    # Iterate over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n), 2):\n",
    "    \n",
    "        # Check if n1 and n2 do NOT have an edge between them\n",
    "        if not G.has_edge(n1, n2):\n",
    "        \n",
    "            in_open_triangle = True\n",
    "            \n",
    "            break\n",
    "            \n",
    "    return in_open_triangle\n",
    "\n",
    "# Compute the number of open triangles in T\n",
    "num_open_triangles = 0\n",
    "\n",
    "# Iterate over all the nodes in T\n",
    "for n in T.nodes():\n",
    "\n",
    "    # Check if the current node is in an open triangle\n",
    "    if node_in_open_triangle(T, n):\n",
    "    \n",
    "        # Increment num_open_triangles\n",
    "        num_open_triangles += 1\n",
    "        \n",
    "print(num_open_triangles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding all maximal cliques of size \"n\"\n",
    "# Now that you've explored triangles (and open triangles), let's move on to the concept of maximal cliques. Maximal cliques are cliques that cannot be extended by adding an adjacent edge, and are a useful property of the graph when finding communities. NetworkX provides a function that allows you to identify the nodes involved in each maximal clique in a graph: nx.find_cliques(G). Play around with the function by using it on T in the IPython Shell, and then try answering the exercise.\n",
    "\n",
    "# Define maximal_cliques()\n",
    "def maximal_cliques(G, size):\n",
    "    \"\"\"\n",
    "    Finds all maximal cliques in graph `G` that are of size `size`.\n",
    "    \"\"\"\n",
    "    mcs = []\n",
    "    for clique in nx.find_cliques(G):\n",
    "        if len(clique) == size:\n",
    "            mcs.append(clique)\n",
    "    return mcs\n",
    "\n",
    "# Check that there are 33 maximal cliques of size 3 in the graph T\n",
    "assert len(maximal_cliques(T, 3)) == 33\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subgraphs I\n",
    "# There may be times when you just want to analyze a subset of nodes in a network. To do so, you can copy them out into another graph object using G.subgraph(nodes), which returns a new graph object (of the same type as the original graph) that is comprised of the iterable of nodes that was passed in.\n",
    "\n",
    "\n",
    "nodes_of_interest = [29, 38, 42]\n",
    "\n",
    "# Define get_nodes_and_nbrs()\n",
    "def get_nodes_and_nbrs(G, nodes_of_interest):\n",
    "    \"\"\"\n",
    "    Returns a subgraph of the graph `G` with only the `nodes_of_interest` and their neighbors.\n",
    "    \"\"\"\n",
    "    nodes_to_draw = []\n",
    "    \n",
    "    # Iterate over the nodes of interest\n",
    "    for n in nodes_of_interest:\n",
    "    \n",
    "        # Append the nodes of interest to nodes_to_draw\n",
    "        nodes_to_draw.append(n)\n",
    "        \n",
    "        # Iterate over all the neighbors of node n\n",
    "        for nbr in G.neighbors(n):\n",
    "        \n",
    "            # Append the neighbors of n to nodes_to_draw\n",
    "            nodes_to_draw.append(nbr)\n",
    "            \n",
    "    return G.subgraph(nodes_to_draw)\n",
    "\n",
    "# Extract the subgraph with the nodes of interest: T_draw\n",
    "T_draw = get_nodes_and_nbrs(T, nodes_of_interest)\n",
    "\n",
    "# Draw the subgraph to the screen\n",
    "nx.draw(T_draw, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subgraphs II\n",
    "# In the previous exercise, we gave you a list of nodes whose neighbors we asked you to extract.\n",
    "# Let's try one more exercise in which you extract nodes that have a particular metadata property and their neighbors. This should hark back to what you've learned about using list comprehensions to find nodes. The exercise will also build your capacity to compose functions that you've already written before.\n",
    "\n",
    "# Extract the nodes of interest: nodes\n",
    "nodes = [n for n, d in T.nodes(data=True) if d['occupation'] == 'celebrity']\n",
    "\n",
    "# Create the set of nodes: nodeset\n",
    "nodeset = set(nodes)\n",
    "\n",
    "# Iterate over nodes\n",
    "for n in nodes:\n",
    "\n",
    "    # Compute the neighbors of n: nbrs\n",
    "    nbrs = T.neighbors(n)\n",
    "    \n",
    "    # Compute the union of nodeset and nbrs: nodeset\n",
    "    nodeset = nodeset.union(nbrs)\n",
    "\n",
    "# Compute the subgraph using nodeset: T_sub\n",
    "T_sub = T.subgraph(nodeset)\n",
    "\n",
    "# Draw T_sub to the screen\n",
    "nx.draw(T_sub, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chapter 4\n",
    "\n",
    "# application of methods, analysis of networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the network\n",
    "\n",
    "len(G.nodes())\n",
    "len(G.edges())\n",
    "\n",
    "\n",
    "# Plot the degree distribution of the GitHub collaboration network\n",
    "plt.hist(list(nx.degree_centrality(G).values()))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the degree distribution of the GitHub collaboration network\n",
    "plt.hist(list(nx.betweenness_centrality(G).values()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MatrixPlot\n",
    "# Let's now practice making some visualizations. The first one will be the MatrixPlot. In a MatrixPlot, the matrix is the representation of the edges.\n",
    "# Python's built-in sorted() function takes an iterable and returns a sorted list (in ascending order, by default). Therefore, to access the largest connected component subgraph, the statement is sliced with [-1].\n",
    "\n",
    "\n",
    "# Calculate the largest connected component subgraph: largest_ccs\n",
    "largest_ccs = sorted(nx.connected_component_subgraphs(G), key=lambda x: len(x))[-1]\n",
    "\n",
    "# Create the customized MatrixPlot object: h\n",
    "h = MatrixPlot(graph=largest_ccs, node_grouping='grouping')\n",
    "\n",
    "# Draw the MatrixPlot to the screen\n",
    "h.draw()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArcPlot\n",
    "# Next up, let's use the ArcPlot to visualize the network. You're going to practice sorting the nodes in the graph as well.\n",
    "\n",
    "\n",
    "# Iterate over all the nodes in G, including the metadata\n",
    "for n, d in G.nodes(data=True):\n",
    "\n",
    "    # Calculate the degree of each node: G.node[n]['degree']\n",
    "    G.node[n]['degree'] = G.degree(n) #nx.degree(G,n)\n",
    "    \n",
    "# Create the ArcPlot object: a\n",
    "a = ArcPlot(graph=G, node_order='degree')\n",
    "\n",
    "# Draw the ArcPlot to the screen\n",
    "a.draw()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CircosPlot\n",
    "\n",
    " \n",
    "# Iterate over all the nodes, including the metadata\n",
    "for n, d in G.nodes(data=True):\n",
    "\n",
    "    # Calculate the degree of each node: G.node[n]['degree']\n",
    "    G.node[n]['degree'] = nx.degree(G,n)\n",
    "\n",
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(G, node_order='degree', node_grouping='grouping', node_color='grouping')\n",
    "\n",
    "# Draw the CircosPlot object to the screen\n",
    "c.draw()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding cliques\n",
    "# You're now going to practice finding cliques in G. Recall that cliques are \"groups of nodes that are fully connected to one another\", while a maximal clique is a clique that cannot be extended by adding another node in the graph.\n",
    "\n",
    "\n",
    "# Calculate the maximal cliques in G: cliques\n",
    "cliques = nx.find_cliques(G)\n",
    "\n",
    "# Count and print the number of maximal cliques in G\n",
    "print(len(list(nx.find_cliques(G))))\n",
    "\n",
    "#Great work! Let's continue by finding a particular maximal clique, and then plotting that clique.\n",
    "\n",
    "# Import necessary modules\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find the author(s) that are part of the largest maximal clique: largest_clique\n",
    "largest_clique = sorted(nx.find_cliques(G), key=lambda x:len(x))[-1]\n",
    "\n",
    "# Create the subgraph of the largest_clique: G_lc\n",
    "G_lc = G.subgraph(largest_clique)\n",
    "\n",
    "# Create the CircosPlot object: c\n",
    "c = CircosPlot(G_lc)\n",
    "\n",
    "# Draw the CircosPlot to the screen\n",
    "c.draw()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding important collaborators\n",
    "# Almost there! You'll now look at important nodes once more. Here, you'll make use of the degree_centrality() and betweenness_centrality() functions in NetworkX to compute each of the respective centrality scores, and then use that information to find the \"important nodes\". In other words, your job in this exercise is to find the user(s) that have collaborated with the most number of users.\n",
    "\n",
    "\n",
    "# Compute the degree centralities of G: deg_cent\n",
    "deg_cent = nx.degree_centrality(G)\n",
    "\n",
    "# Compute the maximum degree centrality: max_dc\n",
    "max_dc = max(deg_cent.values())\n",
    "\n",
    "# Find the user(s) that have collaborated the most: prolific_collaborators\n",
    "prolific_collaborators = [n for n, dc in deg_cent.items() if dc == max_dc]\n",
    "\n",
    "# Print the most prolific collaborator(s)\n",
    "print(prolific_collaborators)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing editing communities\n",
    "# You're now going to combine what you've learned about the BFS algorithm and concept of maximal cliques to visualize the network with an ArcPlot.\n",
    "# The largest maximal clique in the Github user collaboration network has been assigned to the subgraph G_lmc.\n",
    "\n",
    " \n",
    "# Identify the largest maximal clique: largest_max_clique\n",
    "largest_max_clique = set(sorted(nx.find_cliques(G), key=lambda x: len(x))[-1])\n",
    "\n",
    "# Create a subgraph from the largest_max_clique: G_lmc\n",
    "G_lmc = G.subgraph(largest_max_clique)\n",
    "\n",
    "# Go out 1 degree of separation\n",
    "for node in G_lmc.nodes():\n",
    "    G_lmc.add_nodes_from(G.neighbors(node))\n",
    "    G_lmc.add_edges_from(zip([node]*len(G.neighbors(node)), G.neighbors(node)))\n",
    "\n",
    "# Record each node's degree centrality score\n",
    "for n in G_lmc.nodes():\n",
    "    G_lmc.node[n]['degree centrality'] = nx.degree_centrality(G_lmc)[n]\n",
    "        \n",
    "# Create the ArcPlot object: a\n",
    "a = ArcPlot(graph=G_lmc, node_order='degree centrality')\n",
    "\n",
    "# Draw the ArcPlot to the screen\n",
    "a.draw()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommending co-editors who have yet to edit together\n",
    "# Finally, you're going to leverage the concept of open triangles to recommend users on GitHub to collaborate!\n",
    "\n",
    "\n",
    "# Initialize the defaultdict: recommended\n",
    "recommended = defaultdict(int)\n",
    "\n",
    "# Iterate over all the nodes in G\n",
    "for n, d in G.nodes(data=True):\n",
    "\n",
    "    # Iterate over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n), 2):\n",
    "    \n",
    "        # Check whether n1 and n2 do not have an edge\n",
    "        if not G.has_edge(n1, n2):\n",
    "        \n",
    "            # Increment recommended\n",
    "            recommended[(n1, n2)] += 1\n",
    "\n",
    "# Identify the top 10 pairs of users\n",
    "all_counts = sorted(recommended.values())\n",
    "top10_pairs = [pair for pair, count in recommended.items() if count > all_counts[-10]]\n",
    "print(top10_pairs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nx11py36]",
   "language": "python",
   "name": "conda-env-nx11py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
